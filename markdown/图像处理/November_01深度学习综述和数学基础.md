1. 深度学习的主要方向是图像处理、语音识别、自然语言处理等
2. 关注的图像处理方面主要的工业任务涉及图像底层处理、图像分类识别、目标检测、图像分割和图像回归
3. 图像分类识别有几种典型的深度网络，从98年的LeNet开始，后便陆续产生的有AlexNet、VggNet、InceptionNet和ResBet等
4. 目标检测是分类和回归问题的结合，需要确定物体的位置并识别出类型，主要应用是图像增强和图像匹配
5. 图像分割分为实例分割和语义分割，实例分割在语义分割的基础上进一步区分不同的实例



1. 数学基础包括矩阵运算、概率统计、交叉熵、最小二乘优化等

2. 矩阵需要了解的知识是具备属性秩，行秩=列秩=矩阵的秩，满秩阵也叫非奇异矩阵或者可逆矩阵，一般的只有方阵才能进行逆运算，但是非方阵也可以定义广义的逆运算。如果一个矩阵B满足$ABA=A$，$B$可以认为是$A$的广义逆矩阵

3. 矩阵还有常用的是奇异值分解SVD和特征分解，奇异值分解在奇异熵的计算以及主成分降维PCA都有应用

4. 矩阵的特征值计算过程：如果矩阵A是n阶方阵，那么如果满足Ax=mx，其中x是向量，则m是A的一个特征值，x也是一个特征向量。将上述表达式变形为(mE-A)x=0，两边取行列式就可以计算|mE-A|=0，该行列式可以得到一个齐次特征方程组，通过计算即可得到所有特征值

   例如 A= [4,2,-5]      ， 行列式计算为 | m-4 , -2 , 5 | ， 可以先使用两行两列公倍数做差化简，最终可以得到(m-1)m^2=0

   ​	            [6,4,-9]                                     | -6 , m-4, 9 |  = 0

   ​				[5,-3,7]                                       | -5 ,3 , m-7|

   从而可以得到A的特征值为0、0、1，其中0称为二重特征值

   继续计算特征向量，将m=1带回原方程，为(E-A)x=0，可以得到

   [-3,-2,5] [ x1 ]                                               [1, 0 , -1] [ x1 ]                        x1 - x3 =0 

   [-6,-3,9 ] [ x2 ] = 0  ===>   化简 ===> [0, -1 , 1] [ x2 ]= 0  ===>   x2 - x3 =0 

   [-5,-3,8] [x3]                                                 [0 , 0, 0] [x3] 					

   令x1 = 0 ，那么就有 特征向量 k1 (1,1,1),其中k1不为0的整数

   同理 带入m=0，也可以得到另一个线性无关的特征向量k2(1,3,2)

5. 矩阵的迹等于特征值之和，行列式的值等于特征值乘积

6. 矩阵的特征分解：求解特征值和特征向量后，设特征值组成的对角矩阵为Λ，对应顺序组成的特征矩阵为Q，那么就有公式A=QΛQ^(-1)成立，进一步的可以将特征向量标准化，那么还有A=QΛQ^(T)成立

7. 因为特征分解是针对方阵的，所以对于非方阵需要引入奇异值分解SVD，满足A=UΛV^(T)时，其中U和V分别为m×m方阵和n×n的方阵，Λ为m×n的对角矩阵，称U和V分别是矩阵A的左奇异向量和右奇异向量

8. 概率统计，主要需要了解贝叶斯公式、高斯概率分布、条件概率和联合概率分布。在概率论的基础上，即可得到联合熵、交叉熵、相对熵、条件熵和互信息熵

9. 最优化主要涉及最小二乘，用于回归问题较多





​		